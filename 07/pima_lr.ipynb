{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# pima 糖尿病预测作业；\n",
    "采用5折交叉验证，分别用log似然损失和正确率，对Logistic回归模型的正则超参数调优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnants</th>\n",
       "      <th>Plasma_glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skin_fold_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.205066</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.852200</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>2.016662</td>\n",
       "      <td>-0.693761</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-1.332500</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.073567</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.540642</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504422</td>\n",
       "      <td>-2.679076</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.316566</td>\n",
       "      <td>1.549303</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnants  Plasma_glucose_concentration  blood_pressure  \\\n",
       "0   0.639947                      0.866045       -0.031990   \n",
       "1  -0.844885                     -1.205066       -0.528319   \n",
       "2   1.233880                      2.016662       -0.693761   \n",
       "3  -0.844885                     -1.073567       -0.528319   \n",
       "4  -1.141852                      0.504422       -2.679076   \n",
       "\n",
       "   Triceps_skin_fold_thickness  serum_insulin       BMI  \\\n",
       "0                     0.670643      -0.181541  0.166619   \n",
       "1                    -0.012301      -0.181541 -0.852200   \n",
       "2                    -0.012301      -0.181541 -1.332500   \n",
       "3                    -0.695245      -0.540642 -0.633881   \n",
       "4                     0.670643       0.316566  1.549303   \n",
       "\n",
       "   Diabetes_pedigree_function       Age  Target  \n",
       "0                    0.468492  1.425995       1  \n",
       "1                   -0.365061 -0.190672       0  \n",
       "2                    0.604397 -0.105584       1  \n",
       "3                   -0.920763 -1.041549       0  \n",
       "4                    5.484909 -0.020496       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "train = pd.read_csv('FE_pima-indians-diabetes.csv')\n",
    "# 显示头部五条内容，方便查看数据情况\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索与特征工程　见0_EDA_diabetes.ipynb、1_FE_diabetes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据分割\n",
    "训练集测试集8/2分;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 目标数据y\n",
    "y = train['Target']\n",
    "# 训练数据集合X,除了y之外都是\n",
    "X = train.drop(['Target'], axis=1)\n",
    "\n",
    "# 训练测试8/2分，随机种子42.\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 获取各字段名称，方便后面使用\n",
    "columns_name = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 使用LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22643884,  1.11271133, -0.15100003,  0.07127163, -0.13534381,\n",
       "         0.68116965,  0.20030869,  0.39982822]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用默认配置分类器\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 训练\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上测试\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# 模型权重\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72467795,  0.27532205],\n",
       "       [ 0.83113632,  0.16886368],\n",
       "       [ 0.89155287,  0.10844713],\n",
       "       [ 0.84420033,  0.15579967],\n",
       "       [ 0.53548386,  0.46451614],\n",
       "       [ 0.56388091,  0.43611909],\n",
       "       [ 0.9857578 ,  0.0142422 ],\n",
       "       [ 0.61390743,  0.38609257],\n",
       "       [ 0.4226831 ,  0.5773169 ],\n",
       "       [ 0.23730854,  0.76269146],\n",
       "       [ 0.77577896,  0.22422104],\n",
       "       [ 0.10685984,  0.89314016],\n",
       "       [ 0.62260429,  0.37739571],\n",
       "       [ 0.71779258,  0.28220742],\n",
       "       [ 0.92077403,  0.07922597],\n",
       "       [ 0.59422074,  0.40577926],\n",
       "       [ 0.88638976,  0.11361024],\n",
       "       [ 0.92525227,  0.07474773],\n",
       "       [ 0.27360556,  0.72639444],\n",
       "       [ 0.42024042,  0.57975958],\n",
       "       [ 0.81137231,  0.18862769],\n",
       "       [ 0.92324249,  0.07675751],\n",
       "       [ 0.48342538,  0.51657462],\n",
       "       [ 0.90485462,  0.09514538],\n",
       "       [ 0.44079602,  0.55920398],\n",
       "       [ 0.11326737,  0.88673263],\n",
       "       [ 0.89180018,  0.10819982],\n",
       "       [ 0.9704922 ,  0.0295078 ],\n",
       "       [ 0.73685656,  0.26314344],\n",
       "       [ 0.89337599,  0.10662401],\n",
       "       [ 0.07156468,  0.92843532],\n",
       "       [ 0.14303801,  0.85696199],\n",
       "       [ 0.18319825,  0.81680175],\n",
       "       [ 0.3353736 ,  0.6646264 ],\n",
       "       [ 0.4259992 ,  0.5740008 ],\n",
       "       [ 0.27746413,  0.72253587],\n",
       "       [ 0.02470798,  0.97529202],\n",
       "       [ 0.79046636,  0.20953364],\n",
       "       [ 0.55015624,  0.44984376],\n",
       "       [ 0.50814107,  0.49185893],\n",
       "       [ 0.93376342,  0.06623658],\n",
       "       [ 0.4385599 ,  0.5614401 ],\n",
       "       [ 0.4882694 ,  0.5117306 ],\n",
       "       [ 0.69200969,  0.30799031],\n",
       "       [ 0.97332779,  0.02667221],\n",
       "       [ 0.43905482,  0.56094518],\n",
       "       [ 0.35076545,  0.64923455],\n",
       "       [ 0.80714102,  0.19285898],\n",
       "       [ 0.66803689,  0.33196311],\n",
       "       [ 0.03964552,  0.96035448],\n",
       "       [ 0.95947329,  0.04052671],\n",
       "       [ 0.30885747,  0.69114253],\n",
       "       [ 0.16426054,  0.83573946],\n",
       "       [ 0.75372681,  0.24627319],\n",
       "       [ 0.89526854,  0.10473146],\n",
       "       [ 0.95988945,  0.04011055],\n",
       "       [ 0.22997452,  0.77002548],\n",
       "       [ 0.95125673,  0.04874327],\n",
       "       [ 0.5752767 ,  0.4247233 ],\n",
       "       [ 0.23784471,  0.76215529],\n",
       "       [ 0.27359742,  0.72640258],\n",
       "       [ 0.68496377,  0.31503623],\n",
       "       [ 0.80455163,  0.19544837],\n",
       "       [ 0.81026316,  0.18973684],\n",
       "       [ 0.92277547,  0.07722453],\n",
       "       [ 0.36610431,  0.63389569],\n",
       "       [ 0.96055449,  0.03944551],\n",
       "       [ 0.27351395,  0.72648605],\n",
       "       [ 0.96463852,  0.03536148],\n",
       "       [ 0.2167072 ,  0.7832928 ],\n",
       "       [ 0.27968817,  0.72031183],\n",
       "       [ 0.9454683 ,  0.0545317 ],\n",
       "       [ 0.84263698,  0.15736302],\n",
       "       [ 0.88712682,  0.11287318],\n",
       "       [ 0.91394696,  0.08605304],\n",
       "       [ 0.5384127 ,  0.4615873 ],\n",
       "       [ 0.85390392,  0.14609608],\n",
       "       [ 0.86284797,  0.13715203],\n",
       "       [ 0.85604454,  0.14395546],\n",
       "       [ 0.77703841,  0.22296159],\n",
       "       [ 0.33695525,  0.66304475],\n",
       "       [ 0.84585   ,  0.15415   ],\n",
       "       [ 0.94359934,  0.05640066],\n",
       "       [ 0.57536879,  0.42463121],\n",
       "       [ 0.74245712,  0.25754288],\n",
       "       [ 0.13969901,  0.86030099],\n",
       "       [ 0.1012823 ,  0.8987177 ],\n",
       "       [ 0.68065559,  0.31934441],\n",
       "       [ 0.89588622,  0.10411378],\n",
       "       [ 0.92141   ,  0.07859   ],\n",
       "       [ 0.93514601,  0.06485399],\n",
       "       [ 0.78704158,  0.21295842],\n",
       "       [ 0.9644802 ,  0.0355198 ],\n",
       "       [ 0.70057561,  0.29942439],\n",
       "       [ 0.47181181,  0.52818819],\n",
       "       [ 0.36398968,  0.63601032],\n",
       "       [ 0.66169814,  0.33830186],\n",
       "       [ 0.87733855,  0.12266145],\n",
       "       [ 0.32981283,  0.67018717],\n",
       "       [ 0.93265576,  0.06734424],\n",
       "       [ 0.24052674,  0.75947326],\n",
       "       [ 0.9389681 ,  0.0610319 ],\n",
       "       [ 0.23372711,  0.76627289],\n",
       "       [ 0.45432668,  0.54567332],\n",
       "       [ 0.34966344,  0.65033656],\n",
       "       [ 0.75763209,  0.24236791],\n",
       "       [ 0.70987426,  0.29012574],\n",
       "       [ 0.21767168,  0.78232832],\n",
       "       [ 0.87640956,  0.12359044],\n",
       "       [ 0.51930415,  0.48069585],\n",
       "       [ 0.91868696,  0.08131304],\n",
       "       [ 0.64638317,  0.35361683],\n",
       "       [ 0.83759539,  0.16240461],\n",
       "       [ 0.2093341 ,  0.7906659 ],\n",
       "       [ 0.81496126,  0.18503874],\n",
       "       [ 0.69067847,  0.30932153],\n",
       "       [ 0.23251102,  0.76748898],\n",
       "       [ 0.79469532,  0.20530468],\n",
       "       [ 0.94237992,  0.05762008],\n",
       "       [ 0.67014262,  0.32985738],\n",
       "       [ 0.94457037,  0.05542963],\n",
       "       [ 0.68338416,  0.31661584],\n",
       "       [ 0.77339086,  0.22660914],\n",
       "       [ 0.92761989,  0.07238011],\n",
       "       [ 0.72517463,  0.27482537],\n",
       "       [ 0.56509551,  0.43490449],\n",
       "       [ 0.71000411,  0.28999589],\n",
       "       [ 0.11795312,  0.88204688],\n",
       "       [ 0.08179203,  0.91820797],\n",
       "       [ 0.25644861,  0.74355139],\n",
       "       [ 0.272517  ,  0.727483  ],\n",
       "       [ 0.12495974,  0.87504026],\n",
       "       [ 0.91722153,  0.08277847],\n",
       "       [ 0.5394072 ,  0.4605928 ],\n",
       "       [ 0.14490045,  0.85509955],\n",
       "       [ 0.89668195,  0.10331805],\n",
       "       [ 0.84315472,  0.15684528],\n",
       "       [ 0.13944159,  0.86055841],\n",
       "       [ 0.18673141,  0.81326859],\n",
       "       [ 0.98828551,  0.01171449],\n",
       "       [ 0.91871165,  0.08128835],\n",
       "       [ 0.96383632,  0.03616368],\n",
       "       [ 0.79380971,  0.20619029],\n",
       "       [ 0.56562714,  0.43437286],\n",
       "       [ 0.89033737,  0.10966263],\n",
       "       [ 0.76006417,  0.23993583],\n",
       "       [ 0.88966786,  0.11033214],\n",
       "       [ 0.98451641,  0.01548359],\n",
       "       [ 0.60668027,  0.39331973],\n",
       "       [ 0.24061207,  0.75938793],\n",
       "       [ 0.88900134,  0.11099866],\n",
       "       [ 0.56495516,  0.43504484],\n",
       "       [ 0.72793488,  0.27206512],\n",
       "       [ 0.80598011,  0.19401989]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集预测值\n",
    "lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.11271133094]</td>\n",
       "      <td>Plasma_glucose_concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.681169645302]</td>\n",
       "      <td>BMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.399828217334]</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.226438839584]</td>\n",
       "      <td>pregnants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.200308689896]</td>\n",
       "      <td>Diabetes_pedigree_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0712716268218]</td>\n",
       "      <td>Triceps_skin_fold_thickness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.135343807819]</td>\n",
       "      <td>serum_insulin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.15100002588]</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef                       columns\n",
       "1    [1.11271133094]  Plasma_glucose_concentration\n",
       "5   [0.681169645302]                           BMI\n",
       "7   [0.399828217334]                           Age\n",
       "0   [0.226438839584]                     pregnants\n",
       "6   [0.200308689896]    Diabetes_pedigree_function\n",
       "3  [0.0712716268218]   Triceps_skin_fold_thickness\n",
       "4  [-0.135343807819]                 serum_insulin\n",
       "2   [-0.15100002588]                blood_pressure"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看各模型权重\n",
    "fs = pd.DataFrame({'columns':list(columns_name), 'coef':list((lr.coef_.T))})\n",
    "fs.sort_values(by=['coef'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 使用LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "param = {}\n",
    "\n",
    "lr_cv = LogisticRegressionCV(Cs=Cs, cv=5, n_jobs=-1, refit=True)\n",
    "\n",
    "lr_cv.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred_lr_cv= lr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print y_test_pred_lr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71381017,  0.28618983],\n",
       "       [ 0.81692632,  0.18307368],\n",
       "       [ 0.87848664,  0.12151336],\n",
       "       [ 0.81646939,  0.18353061],\n",
       "       [ 0.53324421,  0.46675579],\n",
       "       [ 0.56344206,  0.43655794],\n",
       "       [ 0.98074081,  0.01925919],\n",
       "       [ 0.62195756,  0.37804244],\n",
       "       [ 0.45531706,  0.54468294],\n",
       "       [ 0.27579945,  0.72420055],\n",
       "       [ 0.75972632,  0.24027368],\n",
       "       [ 0.13468439,  0.86531561],\n",
       "       [ 0.61857709,  0.38142291],\n",
       "       [ 0.72119824,  0.27880176],\n",
       "       [ 0.91259695,  0.08740305],\n",
       "       [ 0.60725726,  0.39274274],\n",
       "       [ 0.86917881,  0.13082119],\n",
       "       [ 0.91131297,  0.08868703],\n",
       "       [ 0.31905147,  0.68094853],\n",
       "       [ 0.47425443,  0.52574557],\n",
       "       [ 0.79232196,  0.20767804],\n",
       "       [ 0.90766245,  0.09233755],\n",
       "       [ 0.47352749,  0.52647251],\n",
       "       [ 0.89467968,  0.10532032],\n",
       "       [ 0.46458923,  0.53541077],\n",
       "       [ 0.14662003,  0.85337997],\n",
       "       [ 0.87681068,  0.12318932],\n",
       "       [ 0.96231637,  0.03768363],\n",
       "       [ 0.726228  ,  0.273772  ],\n",
       "       [ 0.88141077,  0.11858923],\n",
       "       [ 0.10132355,  0.89867645],\n",
       "       [ 0.18209622,  0.81790378],\n",
       "       [ 0.20945233,  0.79054767],\n",
       "       [ 0.38057807,  0.61942193],\n",
       "       [ 0.44371449,  0.55628551],\n",
       "       [ 0.30299687,  0.69700313],\n",
       "       [ 0.0322637 ,  0.9677363 ],\n",
       "       [ 0.76858951,  0.23141049],\n",
       "       [ 0.55654855,  0.44345145],\n",
       "       [ 0.54413797,  0.45586203],\n",
       "       [ 0.92471156,  0.07528844],\n",
       "       [ 0.47642679,  0.52357321],\n",
       "       [ 0.50786644,  0.49213356],\n",
       "       [ 0.67859711,  0.32140289],\n",
       "       [ 0.95841441,  0.04158559],\n",
       "       [ 0.44405932,  0.55594068],\n",
       "       [ 0.35541389,  0.64458611],\n",
       "       [ 0.79206173,  0.20793827],\n",
       "       [ 0.65281493,  0.34718507],\n",
       "       [ 0.05866428,  0.94133572],\n",
       "       [ 0.94793437,  0.05206563],\n",
       "       [ 0.32011756,  0.67988244],\n",
       "       [ 0.17285564,  0.82714436],\n",
       "       [ 0.74731797,  0.25268203],\n",
       "       [ 0.88227752,  0.11772248],\n",
       "       [ 0.94923159,  0.05076841],\n",
       "       [ 0.27253769,  0.72746231],\n",
       "       [ 0.93712548,  0.06287452],\n",
       "       [ 0.59639836,  0.40360164],\n",
       "       [ 0.28999211,  0.71000789],\n",
       "       [ 0.30666574,  0.69333426],\n",
       "       [ 0.69271803,  0.30728197],\n",
       "       [ 0.76666175,  0.23333825],\n",
       "       [ 0.79206875,  0.20793125],\n",
       "       [ 0.90550608,  0.09449392],\n",
       "       [ 0.38359626,  0.61640374],\n",
       "       [ 0.95026952,  0.04973048],\n",
       "       [ 0.30247387,  0.69752613],\n",
       "       [ 0.9503288 ,  0.0496712 ],\n",
       "       [ 0.21446214,  0.78553786],\n",
       "       [ 0.28852499,  0.71147501],\n",
       "       [ 0.92892041,  0.07107959],\n",
       "       [ 0.81878109,  0.18121891],\n",
       "       [ 0.87600812,  0.12399188],\n",
       "       [ 0.8958152 ,  0.1041848 ],\n",
       "       [ 0.51647166,  0.48352834],\n",
       "       [ 0.8306794 ,  0.1693206 ],\n",
       "       [ 0.8454543 ,  0.1545457 ],\n",
       "       [ 0.83873434,  0.16126566],\n",
       "       [ 0.75752325,  0.24247675],\n",
       "       [ 0.37887418,  0.62112582],\n",
       "       [ 0.83629023,  0.16370977],\n",
       "       [ 0.93302352,  0.06697648],\n",
       "       [ 0.56408645,  0.43591355],\n",
       "       [ 0.75605078,  0.24394922],\n",
       "       [ 0.18571647,  0.81428353],\n",
       "       [ 0.13083476,  0.86916524],\n",
       "       [ 0.67490405,  0.32509595],\n",
       "       [ 0.87704265,  0.12295735],\n",
       "       [ 0.9166423 ,  0.0833577 ],\n",
       "       [ 0.92468853,  0.07531147],\n",
       "       [ 0.77497048,  0.22502952],\n",
       "       [ 0.95237944,  0.04762056],\n",
       "       [ 0.69259555,  0.30740445],\n",
       "       [ 0.51824118,  0.48175882],\n",
       "       [ 0.39342873,  0.60657127],\n",
       "       [ 0.66976641,  0.33023359],\n",
       "       [ 0.8682956 ,  0.1317044 ],\n",
       "       [ 0.34289681,  0.65710319],\n",
       "       [ 0.91225458,  0.08774542],\n",
       "       [ 0.27673513,  0.72326487],\n",
       "       [ 0.92470547,  0.07529453],\n",
       "       [ 0.26361286,  0.73638714],\n",
       "       [ 0.47284174,  0.52715826],\n",
       "       [ 0.38482522,  0.61517478],\n",
       "       [ 0.73163319,  0.26836681],\n",
       "       [ 0.70942115,  0.29057885],\n",
       "       [ 0.24737874,  0.75262126],\n",
       "       [ 0.85573643,  0.14426357],\n",
       "       [ 0.52351408,  0.47648592],\n",
       "       [ 0.9062129 ,  0.0937871 ],\n",
       "       [ 0.63985864,  0.36014136],\n",
       "       [ 0.82045546,  0.17954454],\n",
       "       [ 0.21359416,  0.78640584],\n",
       "       [ 0.79868614,  0.20131386],\n",
       "       [ 0.70067205,  0.29932795],\n",
       "       [ 0.28908254,  0.71091746],\n",
       "       [ 0.78470813,  0.21529187],\n",
       "       [ 0.92855169,  0.07144831],\n",
       "       [ 0.66827454,  0.33172546],\n",
       "       [ 0.9322404 ,  0.0677596 ],\n",
       "       [ 0.6768326 ,  0.3231674 ],\n",
       "       [ 0.74845823,  0.25154177],\n",
       "       [ 0.9176479 ,  0.0823521 ],\n",
       "       [ 0.73035057,  0.26964943],\n",
       "       [ 0.53813647,  0.46186353],\n",
       "       [ 0.70102705,  0.29897295],\n",
       "       [ 0.14811377,  0.85188623],\n",
       "       [ 0.11800012,  0.88199988],\n",
       "       [ 0.27398598,  0.72601402],\n",
       "       [ 0.31509183,  0.68490817],\n",
       "       [ 0.14854426,  0.85145574],\n",
       "       [ 0.90721737,  0.09278263],\n",
       "       [ 0.5303435 ,  0.4696565 ],\n",
       "       [ 0.16942994,  0.83057006],\n",
       "       [ 0.87835391,  0.12164609],\n",
       "       [ 0.81790657,  0.18209343],\n",
       "       [ 0.16145205,  0.83854795],\n",
       "       [ 0.2246225 ,  0.7753775 ],\n",
       "       [ 0.98380889,  0.01619111],\n",
       "       [ 0.90542955,  0.09457045],\n",
       "       [ 0.95229076,  0.04770924],\n",
       "       [ 0.78001906,  0.21998094],\n",
       "       [ 0.5399984 ,  0.4600016 ],\n",
       "       [ 0.87996149,  0.12003851],\n",
       "       [ 0.74455574,  0.25544426],\n",
       "       [ 0.870095  ,  0.129905  ],\n",
       "       [ 0.97948515,  0.02051485],\n",
       "       [ 0.60423064,  0.39576936],\n",
       "       [ 0.27014719,  0.72985281],\n",
       "       [ 0.87980986,  0.12019014],\n",
       "       [ 0.57143947,  0.42856053],\n",
       "       [ 0.69086116,  0.30913884],\n",
       "       [ 0.78718295,  0.21281705]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76623376623376627"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76623376623376627"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正确率评价\n",
    "lr.score(X_test, y_test)\n",
    "lr_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.52264348158\n",
      "8.0740775596\n"
     ]
    }
   ],
   "source": [
    "# log似然损失评价\n",
    "from sklearn.metrics import log_loss\n",
    "print log_loss(y_test, y_test_pred_lr)\n",
    "print log_loss(y_test, y_test_pred_lr_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('logloss of each fold is:', array([ 0.51946855,  0.44590087,  0.48482846,  0.48318246,  0.46157091]))\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "loss = cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "\n",
    "print('logloss of each fold is:',-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.15151515  1.        ] [ 0.          0.61818182  1.        ] [2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# roc\n",
    "from sklearn.metrics import roc_curve\n",
    "lr_cv_score = lr_cv.score(X_test, y_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_lr_cv)\n",
    "print fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logloss正则参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 正则/参数范围\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "tuned_para = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr.set_params(solver='liblinear')\n",
    "#这里用负log似然函数评价\n",
    "grid = GridSearchCV(lr, tuned_para, cv=5,scoring='neg_log_loss')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best score:', 0.47873489280312914)\n",
      "('best params:', {'penalty': 'l1', 'C': 1})\n"
     ]
    }
   ],
   "source": [
    "print('best score:', -grid.best_score_)\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBIlDBERieT/A7Yp/icqGY6hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51e272a610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CV误差曲线\n",
    "test_means = grid.cv_results_['mean_test_score']\n",
    "test_stds = grid.cv_results_['std_test_score']\n",
    "train_means = grid.cv_results_['mean_train_score']\n",
    "train_stds = grid.cv_results_['std_train_score']\n",
    "\n",
    "#plot results\n",
    "n_Cs = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)\n",
    "train_scores = np.array(train_means).reshape(n_Cs,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)\n",
    "train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "\n",
    "for i,value in enumerate(penaltys):\n",
    "    plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i], label=penaltys[i]+'Test')\n",
    "    plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i], label=penaltys[i]+'Train')\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()   \n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('logloss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正确率调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 正则/参数范围\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "tuned_para = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr.set_params(solver='liblinear')\n",
    "#这里用负log似然函数评价\n",
    "lr_cv = GridSearchCV(lr, tuned_para, cv=5,scoring='accuracy')\n",
    "lr_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best score:', 0.76710097719869708)\n",
      "('best params:', {'penalty': 'l1', 'C': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00319381,  0.00234141,  0.0019927 ,  0.00186048,  0.00184197,\n",
       "         0.00169859,  0.00176125,  0.001689  ,  0.00211692,  0.00176001]),\n",
       " 'mean_score_time': array([ 0.00192285,  0.00048461,  0.00038495,  0.00034499,  0.00033665,\n",
       "         0.00032201,  0.00031819,  0.00031943,  0.00044022,  0.0003356 ]),\n",
       " 'mean_test_score': array([ 0.76547231,  0.76221498,  0.76710098,  0.76384365,  0.76384365,\n",
       "         0.76221498,  0.76221498,  0.76221498,  0.76221498,  0.76221498]),\n",
       " 'mean_train_score': array([ 0.76954577,  0.77239959,  0.77524926,  0.77361993,  0.77280692,\n",
       "         0.77280526,  0.77362076,  0.77362076,  0.77402809,  0.77402809]),\n",
       " 'param_C': masked_array(data = [0.1 0.1 1 1 10 10 100 100 1000 1000],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_penalty': masked_array(data = ['l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'},\n",
       "  {'C': 1000, 'penalty': 'l1'},\n",
       "  {'C': 1000, 'penalty': 'l2'}),\n",
       " 'rank_test_score': array([2, 5, 1, 3, 3, 5, 5, 5, 5, 5], dtype=int32),\n",
       " 'split0_test_score': array([ 0.73387097,  0.72580645,  0.73387097,  0.72580645,  0.72580645,\n",
       "         0.72580645,  0.72580645,  0.72580645,  0.72580645,  0.72580645]),\n",
       " 'split0_train_score': array([ 0.7755102 ,  0.78367347,  0.78367347,  0.78163265,  0.78367347,\n",
       "         0.78163265,  0.78367347,  0.78367347,  0.78367347,  0.78367347]),\n",
       " 'split1_test_score': array([ 0.79674797,  0.80487805,  0.80487805,  0.80487805,  0.80487805,\n",
       "         0.80487805,  0.80487805,  0.80487805,  0.80487805,  0.80487805]),\n",
       " 'split1_train_score': array([ 0.76171079,  0.75967413,  0.76578411,  0.76374745,  0.76171079,\n",
       "         0.76171079,  0.76171079,  0.76171079,  0.76374745,  0.76374745]),\n",
       " 'split2_test_score': array([ 0.7804878 ,  0.75609756,  0.75609756,  0.74796748,  0.74796748,\n",
       "         0.7398374 ,  0.7398374 ,  0.7398374 ,  0.7398374 ,  0.7398374 ]),\n",
       " 'split2_train_score': array([ 0.76985743,  0.77596741,  0.78004073,  0.77800407,  0.77596741,\n",
       "         0.77596741,  0.77800407,  0.77800407,  0.77800407,  0.77800407]),\n",
       " 'split3_test_score': array([ 0.73770492,  0.73770492,  0.74590164,  0.74590164,  0.74590164,\n",
       "         0.74590164,  0.74590164,  0.74590164,  0.74590164,  0.74590164]),\n",
       " 'split3_train_score': array([ 0.77642276,  0.7804878 ,  0.77845528,  0.77642276,  0.77845528,\n",
       "         0.77845528,  0.77845528,  0.77845528,  0.77845528,  0.77845528]),\n",
       " 'split4_test_score': array([ 0.77868852,  0.78688525,  0.79508197,  0.79508197,  0.79508197,\n",
       "         0.79508197,  0.79508197,  0.79508197,  0.79508197,  0.79508197]),\n",
       " 'split4_train_score': array([ 0.76422764,  0.76219512,  0.76829268,  0.76829268,  0.76422764,\n",
       "         0.76626016,  0.76626016,  0.76626016,  0.76626016,  0.76626016]),\n",
       " 'std_fit_time': array([  5.75179086e-04,   3.84434551e-04,   1.91677684e-04,\n",
       "          1.88362363e-04,   5.54025273e-05,   3.82025433e-05,\n",
       "          4.11224432e-05,   2.44480321e-05,   4.40349783e-04,\n",
       "          5.90933807e-05]),\n",
       " 'std_score_time': array([  2.59831707e-03,   1.50410087e-04,   7.52106288e-05,\n",
       "          1.04131890e-05,   1.81072593e-05,   6.40915971e-06,\n",
       "          4.06180180e-06,   2.61783166e-06,   1.55875843e-04,\n",
       "          2.01998936e-05]),\n",
       " 'std_test_score': array([ 0.02511387,  0.02966684,  0.02789282,  0.03062446,  0.03062446,\n",
       "         0.03162531,  0.03162531,  0.03162531,  0.03162531,  0.03162531]),\n",
       " 'std_train_score': array([ 0.00587595,  0.00970894,  0.0069597 ,  0.00658977,  0.00844633,\n",
       "         0.00756003,  0.00824219,  0.00824219,  0.00767429,  0.00767429])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best score:', lr_cv.best_score_)\n",
    "print('best params:', lr_cv.best_params_)\n",
    "lr_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f6b27d855e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlr_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# scores_：dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "Cs = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 2\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in lr_cv.cv_results_[1]:\n",
    "    scores[0][j] = np.mean(i,axis=0)\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "mse_mean = np.mean(scores, axis = 0)\n",
    "print (mse_mean)\n",
    "plt.plot(Cs, mse_mean.reshape(n_Cs,1)) \n",
    "#plt(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
