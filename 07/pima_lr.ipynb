{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# pima 糖尿病预测作业；\n",
    "采用5折交叉验证，分别用log似然损失和正确率，对Logistic回归模型的正则超参数调优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnants</th>\n",
       "      <th>Plasma_glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>Triceps_skin_fold_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes_pedigree_function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.205066</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-0.852200</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>2.016662</td>\n",
       "      <td>-0.693761</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>-0.181541</td>\n",
       "      <td>-1.332500</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.073567</td>\n",
       "      <td>-0.528319</td>\n",
       "      <td>-0.695245</td>\n",
       "      <td>-0.540642</td>\n",
       "      <td>-0.633881</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504422</td>\n",
       "      <td>-2.679076</td>\n",
       "      <td>0.670643</td>\n",
       "      <td>0.316566</td>\n",
       "      <td>1.549303</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnants  Plasma_glucose_concentration  blood_pressure  \\\n",
       "0   0.639947                      0.866045       -0.031990   \n",
       "1  -0.844885                     -1.205066       -0.528319   \n",
       "2   1.233880                      2.016662       -0.693761   \n",
       "3  -0.844885                     -1.073567       -0.528319   \n",
       "4  -1.141852                      0.504422       -2.679076   \n",
       "\n",
       "   Triceps_skin_fold_thickness  serum_insulin       BMI  \\\n",
       "0                     0.670643      -0.181541  0.166619   \n",
       "1                    -0.012301      -0.181541 -0.852200   \n",
       "2                    -0.012301      -0.181541 -1.332500   \n",
       "3                    -0.695245      -0.540642 -0.633881   \n",
       "4                     0.670643       0.316566  1.549303   \n",
       "\n",
       "   Diabetes_pedigree_function       Age  Target  \n",
       "0                    0.468492  1.425995       1  \n",
       "1                   -0.365061 -0.190672       0  \n",
       "2                    0.604397 -0.105584       1  \n",
       "3                   -0.920763 -1.041549       0  \n",
       "4                    5.484909 -0.020496       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('FE_pima-indians-diabetes.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索与特征工程　见0_EDA_diabetes.ipynb、1_FE_diabetes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据分割\n",
    "训练集测试集8/2分;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = train['Target']\n",
    "X = train.drop(['Target'], axis=1)\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "columns_name = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22643884,  1.11271133, -0.15100003,  0.07127163, -0.13534381,\n",
       "         0.68116965,  0.20030869,  0.39982822]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用默认配置分类器\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 训练\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上测试\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# 模型权重\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72467795,  0.27532205],\n",
       "       [ 0.83113632,  0.16886368],\n",
       "       [ 0.89155287,  0.10844713],\n",
       "       [ 0.84420033,  0.15579967],\n",
       "       [ 0.53548386,  0.46451614],\n",
       "       [ 0.56388091,  0.43611909],\n",
       "       [ 0.9857578 ,  0.0142422 ],\n",
       "       [ 0.61390743,  0.38609257],\n",
       "       [ 0.4226831 ,  0.5773169 ],\n",
       "       [ 0.23730854,  0.76269146],\n",
       "       [ 0.77577896,  0.22422104],\n",
       "       [ 0.10685984,  0.89314016],\n",
       "       [ 0.62260429,  0.37739571],\n",
       "       [ 0.71779258,  0.28220742],\n",
       "       [ 0.92077403,  0.07922597],\n",
       "       [ 0.59422074,  0.40577926],\n",
       "       [ 0.88638976,  0.11361024],\n",
       "       [ 0.92525227,  0.07474773],\n",
       "       [ 0.27360556,  0.72639444],\n",
       "       [ 0.42024042,  0.57975958],\n",
       "       [ 0.81137231,  0.18862769],\n",
       "       [ 0.92324249,  0.07675751],\n",
       "       [ 0.48342538,  0.51657462],\n",
       "       [ 0.90485462,  0.09514538],\n",
       "       [ 0.44079602,  0.55920398],\n",
       "       [ 0.11326737,  0.88673263],\n",
       "       [ 0.89180018,  0.10819982],\n",
       "       [ 0.9704922 ,  0.0295078 ],\n",
       "       [ 0.73685656,  0.26314344],\n",
       "       [ 0.89337599,  0.10662401],\n",
       "       [ 0.07156468,  0.92843532],\n",
       "       [ 0.14303801,  0.85696199],\n",
       "       [ 0.18319825,  0.81680175],\n",
       "       [ 0.3353736 ,  0.6646264 ],\n",
       "       [ 0.4259992 ,  0.5740008 ],\n",
       "       [ 0.27746413,  0.72253587],\n",
       "       [ 0.02470798,  0.97529202],\n",
       "       [ 0.79046636,  0.20953364],\n",
       "       [ 0.55015624,  0.44984376],\n",
       "       [ 0.50814107,  0.49185893],\n",
       "       [ 0.93376342,  0.06623658],\n",
       "       [ 0.4385599 ,  0.5614401 ],\n",
       "       [ 0.4882694 ,  0.5117306 ],\n",
       "       [ 0.69200969,  0.30799031],\n",
       "       [ 0.97332779,  0.02667221],\n",
       "       [ 0.43905482,  0.56094518],\n",
       "       [ 0.35076545,  0.64923455],\n",
       "       [ 0.80714102,  0.19285898],\n",
       "       [ 0.66803689,  0.33196311],\n",
       "       [ 0.03964552,  0.96035448],\n",
       "       [ 0.95947329,  0.04052671],\n",
       "       [ 0.30885747,  0.69114253],\n",
       "       [ 0.16426054,  0.83573946],\n",
       "       [ 0.75372681,  0.24627319],\n",
       "       [ 0.89526854,  0.10473146],\n",
       "       [ 0.95988945,  0.04011055],\n",
       "       [ 0.22997452,  0.77002548],\n",
       "       [ 0.95125673,  0.04874327],\n",
       "       [ 0.5752767 ,  0.4247233 ],\n",
       "       [ 0.23784471,  0.76215529],\n",
       "       [ 0.27359742,  0.72640258],\n",
       "       [ 0.68496377,  0.31503623],\n",
       "       [ 0.80455163,  0.19544837],\n",
       "       [ 0.81026316,  0.18973684],\n",
       "       [ 0.92277547,  0.07722453],\n",
       "       [ 0.36610431,  0.63389569],\n",
       "       [ 0.96055449,  0.03944551],\n",
       "       [ 0.27351395,  0.72648605],\n",
       "       [ 0.96463852,  0.03536148],\n",
       "       [ 0.2167072 ,  0.7832928 ],\n",
       "       [ 0.27968817,  0.72031183],\n",
       "       [ 0.9454683 ,  0.0545317 ],\n",
       "       [ 0.84263698,  0.15736302],\n",
       "       [ 0.88712682,  0.11287318],\n",
       "       [ 0.91394696,  0.08605304],\n",
       "       [ 0.5384127 ,  0.4615873 ],\n",
       "       [ 0.85390392,  0.14609608],\n",
       "       [ 0.86284797,  0.13715203],\n",
       "       [ 0.85604454,  0.14395546],\n",
       "       [ 0.77703841,  0.22296159],\n",
       "       [ 0.33695525,  0.66304475],\n",
       "       [ 0.84585   ,  0.15415   ],\n",
       "       [ 0.94359934,  0.05640066],\n",
       "       [ 0.57536879,  0.42463121],\n",
       "       [ 0.74245712,  0.25754288],\n",
       "       [ 0.13969901,  0.86030099],\n",
       "       [ 0.1012823 ,  0.8987177 ],\n",
       "       [ 0.68065559,  0.31934441],\n",
       "       [ 0.89588622,  0.10411378],\n",
       "       [ 0.92141   ,  0.07859   ],\n",
       "       [ 0.93514601,  0.06485399],\n",
       "       [ 0.78704158,  0.21295842],\n",
       "       [ 0.9644802 ,  0.0355198 ],\n",
       "       [ 0.70057561,  0.29942439],\n",
       "       [ 0.47181181,  0.52818819],\n",
       "       [ 0.36398968,  0.63601032],\n",
       "       [ 0.66169814,  0.33830186],\n",
       "       [ 0.87733855,  0.12266145],\n",
       "       [ 0.32981283,  0.67018717],\n",
       "       [ 0.93265576,  0.06734424],\n",
       "       [ 0.24052674,  0.75947326],\n",
       "       [ 0.9389681 ,  0.0610319 ],\n",
       "       [ 0.23372711,  0.76627289],\n",
       "       [ 0.45432668,  0.54567332],\n",
       "       [ 0.34966344,  0.65033656],\n",
       "       [ 0.75763209,  0.24236791],\n",
       "       [ 0.70987426,  0.29012574],\n",
       "       [ 0.21767168,  0.78232832],\n",
       "       [ 0.87640956,  0.12359044],\n",
       "       [ 0.51930415,  0.48069585],\n",
       "       [ 0.91868696,  0.08131304],\n",
       "       [ 0.64638317,  0.35361683],\n",
       "       [ 0.83759539,  0.16240461],\n",
       "       [ 0.2093341 ,  0.7906659 ],\n",
       "       [ 0.81496126,  0.18503874],\n",
       "       [ 0.69067847,  0.30932153],\n",
       "       [ 0.23251102,  0.76748898],\n",
       "       [ 0.79469532,  0.20530468],\n",
       "       [ 0.94237992,  0.05762008],\n",
       "       [ 0.67014262,  0.32985738],\n",
       "       [ 0.94457037,  0.05542963],\n",
       "       [ 0.68338416,  0.31661584],\n",
       "       [ 0.77339086,  0.22660914],\n",
       "       [ 0.92761989,  0.07238011],\n",
       "       [ 0.72517463,  0.27482537],\n",
       "       [ 0.56509551,  0.43490449],\n",
       "       [ 0.71000411,  0.28999589],\n",
       "       [ 0.11795312,  0.88204688],\n",
       "       [ 0.08179203,  0.91820797],\n",
       "       [ 0.25644861,  0.74355139],\n",
       "       [ 0.272517  ,  0.727483  ],\n",
       "       [ 0.12495974,  0.87504026],\n",
       "       [ 0.91722153,  0.08277847],\n",
       "       [ 0.5394072 ,  0.4605928 ],\n",
       "       [ 0.14490045,  0.85509955],\n",
       "       [ 0.89668195,  0.10331805],\n",
       "       [ 0.84315472,  0.15684528],\n",
       "       [ 0.13944159,  0.86055841],\n",
       "       [ 0.18673141,  0.81326859],\n",
       "       [ 0.98828551,  0.01171449],\n",
       "       [ 0.91871165,  0.08128835],\n",
       "       [ 0.96383632,  0.03616368],\n",
       "       [ 0.79380971,  0.20619029],\n",
       "       [ 0.56562714,  0.43437286],\n",
       "       [ 0.89033737,  0.10966263],\n",
       "       [ 0.76006417,  0.23993583],\n",
       "       [ 0.88966786,  0.11033214],\n",
       "       [ 0.98451641,  0.01548359],\n",
       "       [ 0.60668027,  0.39331973],\n",
       "       [ 0.24061207,  0.75938793],\n",
       "       [ 0.88900134,  0.11099866],\n",
       "       [ 0.56495516,  0.43504484],\n",
       "       [ 0.72793488,  0.27206512],\n",
       "       [ 0.80598011,  0.19401989]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集腿硬预测值\n",
    "lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.11271133094]</td>\n",
       "      <td>Plasma_glucose_concentration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.681169645302]</td>\n",
       "      <td>BMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.399828217334]</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.226438839584]</td>\n",
       "      <td>pregnants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.200308689896]</td>\n",
       "      <td>Diabetes_pedigree_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0712716268218]</td>\n",
       "      <td>Triceps_skin_fold_thickness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.135343807819]</td>\n",
       "      <td>serum_insulin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.15100002588]</td>\n",
       "      <td>blood_pressure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef                       columns\n",
       "1    [1.11271133094]  Plasma_glucose_concentration\n",
       "5   [0.681169645302]                           BMI\n",
       "7   [0.399828217334]                           Age\n",
       "0   [0.226438839584]                     pregnants\n",
       "6   [0.200308689896]    Diabetes_pedigree_function\n",
       "3  [0.0712716268218]   Triceps_skin_fold_thickness\n",
       "4  [-0.135343807819]                 serum_insulin\n",
       "2   [-0.15100002588]                blood_pressure"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看各模型权重\n",
    "fs = pd.DataFrame({'columns':list(columns_name), 'coef':list((lr.coef_.T))})\n",
    "fs.sort_values(by=['coef'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75324675324675328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正确率评价\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5226434815773988"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log似然损失评价\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_test_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('logloss of each fold is:', array([ 0.51946855,  0.44590087,  0.48482846,  0.48318246,  0.46157091]))\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "loss = cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_log_loss')\n",
    "\n",
    "print('logloss of each fold is:',-loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logloss正则参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 正则/参数范围\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "tuned_para = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr.set_params(solver='liblinear')\n",
    "#这里用负log似然函数评价\n",
    "grid = GridSearchCV(lr, tuned_para, cv=5,scoring='neg_log_loss')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best score:', 0.47873280196205426)\n",
      "('best params:', {'penalty': 'l1', 'C': 1})\n"
     ]
    }
   ],
   "source": [
    "print('best score:', -grid.best_score_)\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5XoWeeeShh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1fc4d1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CV误差曲线\n",
    "test_means = grid.cv_results_['mean_test_score']\n",
    "test_stds = grid.cv_results_['std_test_score']\n",
    "train_means = grid.cv_results_['mean_train_score']\n",
    "train_stds = grid.cv_results_['std_train_score']\n",
    "\n",
    "#plot results\n",
    "n_Cs = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)\n",
    "train_scores = np.array(train_means).reshape(n_Cs,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)\n",
    "train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "\n",
    "for i,value in enumerate(penaltys):\n",
    "    plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i], label=penaltys[i]+'Test')\n",
    "    plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i], label=penaltys[i]+'Train')\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()   \n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('logloss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正确率调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 正则/参数范围\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "tuned_para = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr.set_params(solver='liblinear')\n",
    "#这里用负log似然函数评价\n",
    "lr_cv = GridSearchCV(lr, tuned_para, cv=5,scoring='accuracy')\n",
    "lr_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best score:', 0.76710097719869708)\n",
      "('best params:', {'penalty': 'l1', 'C': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.00436263,  0.00276146,  0.00231776,  0.0019516 ,  0.00211763,\n",
       "         0.00189481,  0.00219278,  0.00195956,  0.00191703,  0.00172834]),\n",
       " 'mean_score_time': array([ 0.00086703,  0.00054173,  0.00045562,  0.00039277,  0.00038495,\n",
       "         0.00038018,  0.00046105,  0.00035038,  0.00034876,  0.00033121]),\n",
       " 'mean_test_score': array([ 0.76547231,  0.76221498,  0.76710098,  0.76384365,  0.76384365,\n",
       "         0.76221498,  0.76221498,  0.76221498,  0.76221498,  0.76221498]),\n",
       " 'mean_train_score': array([ 0.76954577,  0.77239959,  0.77524926,  0.77361993,  0.77280692,\n",
       "         0.77280526,  0.77362076,  0.77362076,  0.77402809,  0.77402809]),\n",
       " 'param_C': masked_array(data = [0.1 0.1 1 1 10 10 100 100 1000 1000],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_penalty': masked_array(data = ['l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2' 'l1' 'l2'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'},\n",
       "  {'C': 1000, 'penalty': 'l1'},\n",
       "  {'C': 1000, 'penalty': 'l2'}),\n",
       " 'rank_test_score': array([2, 5, 1, 3, 3, 5, 5, 5, 5, 5], dtype=int32),\n",
       " 'split0_test_score': array([ 0.73387097,  0.72580645,  0.73387097,  0.72580645,  0.72580645,\n",
       "         0.72580645,  0.72580645,  0.72580645,  0.72580645,  0.72580645]),\n",
       " 'split0_train_score': array([ 0.7755102 ,  0.78367347,  0.78367347,  0.78163265,  0.78367347,\n",
       "         0.78163265,  0.78367347,  0.78367347,  0.78367347,  0.78367347]),\n",
       " 'split1_test_score': array([ 0.79674797,  0.80487805,  0.80487805,  0.80487805,  0.80487805,\n",
       "         0.80487805,  0.80487805,  0.80487805,  0.80487805,  0.80487805]),\n",
       " 'split1_train_score': array([ 0.76171079,  0.75967413,  0.76578411,  0.76374745,  0.76171079,\n",
       "         0.76171079,  0.76171079,  0.76171079,  0.76374745,  0.76374745]),\n",
       " 'split2_test_score': array([ 0.7804878 ,  0.75609756,  0.75609756,  0.74796748,  0.74796748,\n",
       "         0.7398374 ,  0.7398374 ,  0.7398374 ,  0.7398374 ,  0.7398374 ]),\n",
       " 'split2_train_score': array([ 0.76985743,  0.77596741,  0.78004073,  0.77800407,  0.77596741,\n",
       "         0.77596741,  0.77800407,  0.77800407,  0.77800407,  0.77800407]),\n",
       " 'split3_test_score': array([ 0.73770492,  0.73770492,  0.74590164,  0.74590164,  0.74590164,\n",
       "         0.74590164,  0.74590164,  0.74590164,  0.74590164,  0.74590164]),\n",
       " 'split3_train_score': array([ 0.77642276,  0.7804878 ,  0.77845528,  0.77642276,  0.77845528,\n",
       "         0.77845528,  0.77845528,  0.77845528,  0.77845528,  0.77845528]),\n",
       " 'split4_test_score': array([ 0.77868852,  0.78688525,  0.79508197,  0.79508197,  0.79508197,\n",
       "         0.79508197,  0.79508197,  0.79508197,  0.79508197,  0.79508197]),\n",
       " 'split4_train_score': array([ 0.76422764,  0.76219512,  0.76829268,  0.76829268,  0.76422764,\n",
       "         0.76626016,  0.76626016,  0.76626016,  0.76626016,  0.76626016]),\n",
       " 'std_fit_time': array([  1.31521866e-03,   7.48780422e-04,   2.04760594e-04,\n",
       "          9.57771797e-05,   9.02365661e-05,   7.71071782e-05,\n",
       "          3.27412081e-04,   2.13333076e-04,   5.83073779e-05,\n",
       "          2.59932678e-05]),\n",
       " 'std_score_time': array([  1.72067044e-04,   1.74936301e-04,   3.83630237e-05,\n",
       "          3.37358835e-05,   9.82168802e-06,   4.33267897e-05,\n",
       "          1.56739166e-04,   9.32652525e-06,   1.72417354e-05,\n",
       "          9.33115616e-06]),\n",
       " 'std_test_score': array([ 0.02511387,  0.02966684,  0.02789282,  0.03062446,  0.03062446,\n",
       "         0.03162531,  0.03162531,  0.03162531,  0.03162531,  0.03162531]),\n",
       " 'std_train_score': array([ 0.00587595,  0.00970894,  0.0069597 ,  0.00658977,  0.00844633,\n",
       "         0.00756003,  0.00824219,  0.00824219,  0.00767429,  0.00767429])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('best score:', lr_cv.best_score_)\n",
    "print('best params:', lr_cv.best_params_)\n",
    "lr_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_PredictScorer' object does not support indexing",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dfc204bfb64d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlr_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_PredictScorer' object does not support indexing"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# scores_：dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold,\n",
    "# Each dict value has shape (n_folds, len(Cs))\n",
    "Cs = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "n_Cs = len(Cs)\n",
    "n_classes = 2\n",
    "scores =  np.zeros((n_classes,n_Cs))\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in lr_cv.cv_results_[1]:\n",
    "    scores[0][j] = np.mean(i,axis=0)\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "mse_mean = np.mean(scores, axis = 0)\n",
    "print (mse_mean)\n",
    "plt.plot(Cs, mse_mean.reshape(n_Cs,1)) \n",
    "#plt(np.log10(reg.Cs)*np.ones(3), [0.28, 0.29, 0.30])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "#print ('C is:',lr_cv.C_)  #对多类分类问题，每个类别的分类器有一个C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
