1. 对连续型特征，可以用哪个函数可视化其分布？（给出你最常用的一个即可），并根据代码运行结果给出示例。（10分） 
    
    subplots()/violin()/
    > import seaborn as sn
    >
    > sn.violin(data=train['feature_01' ','y'], x='feature_01', y='y'')

2. 对两个连续型特征，可以用哪个函数得到这两个特征之间的相关性？根据代码运行结果，给出示例。（10分）
    1. 两个数值特征之间相关性、先用plt.scatter()散点图看下，再用sns.heatmap()看具体相关性；
    2. 数值特征与类型特征，可以用lmplot()函数中的hue参数指定感兴趣的类别特征，也可以用violinplot/boxplot表示在一个类型特征值下，另一个数值特征分布；
    3. 类别特征与类别特征，通过设置hue参数，在图形中加入类别维度。除了使用图形类别分析之外，还可以使用统计学的传统工具：列联表（contingency table），又称交叉制表，使用表格表示多个类变量的频率分布；
    > seaborn.heatmap()
    > import matplotlib.pyplot as plt 
    > plt.scatter(data[a], data[b], s=10, alpha=.5)
 
3. 如果发现特征之间有较强的相关性，在选择线性回归模型时应该采取什么措施。（10分）
    
    答:
    (1)如果输入特征维度高，且是稀疏线性，使用lasso;否则使用共线性不敏感的岭回归；

    （2）采用逐步回归结合主观分析的方法，从少到多的做特征选择

    （3）从共线问题的自变量中剔除一些不重要的变量
    
    [线性模型如何解决特征相关性问题?从统计学角度看](https://www.zhihu.com/question/27974196);
    [特征工程:特征相关性分析](https://blog.csdn.net/qq_36874480/article/details/80272047)
 
4. 当采用带正则的模型以及采用随机梯度下降优化算法时，需要对输入（连续型）特征进行去量纲预处理。课程代码给出了用标准化（StandardScaler）的结果，请改成最小最大缩放（MinMaxScaler）去量纲 （10分），并重新训练最小二乘线性回归、岭回归、和Lasso模型（30分）。
 
5. 代码中给出了岭回归（RidgeCV）和Lasso（LassoCV）超参数（alpha_）调优的过程，请结合两个最佳模型以及最小二乘线性回归模型的结果，给出什么场合应该用岭回归，什么场合用Lasso，什么场合用最小二乘